<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jiarus</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jiarus.github.io/"/>
  <updated>2019-08-11T02:36:48.123Z</updated>
  <id>https://jiarus.github.io/</id>
  
  <author>
    <name>fever</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>计算机CPU性能提升</title>
    <link href="https://jiarus.github.io/2019/07/28/%E8%AE%A1%E7%AE%97%E6%9C%BACPU%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87/"/>
    <id>https://jiarus.github.io/2019/07/28/计算机CPU性能提升/</id>
    <published>2019-07-27T20:16:00.000Z</published>
    <updated>2019-08-11T02:36:48.123Z</updated>
    
    <content type="html"><![CDATA[<p>CPU提升的途径：增加晶体管密度、提升CPU主频（晶体管开关的速度）</p><p><u><em>增加晶体管密度就需要把晶体管造的更小，这就是所谓的”制程”</em></u></p><p>CPU提升带来的是功率的增加：</p><p>CPU功率 <strong><em>～=1/2x负载电容x电压的平方x开关频率x晶体管数量</em></strong></p><p>*<u>降低CPU电压最容易提升计算机的续航</u>*</p><hr><p><strong>但仅靠提升CPU性能会遇到瓶颈，就需要采用CPU并行提高性能</strong></p><p>并行也会需要瓶颈，正如阿姆达尔定律（Amdahl’s Law）</p><p><em>优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间</em></p><p>一个程序可以分解为多个CPU的任务来处理，处理结束需要将多个CPU处理结果汇总在一起</p><p><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5oa9jvga5j30w20kmta0.jpg" alt></p><p>100/4 + 20 = 45<br>100/100 + 20 = 21</p><p>可以看出仅靠增加CPU是会遇到瓶颈的，不受影响的执行时间无法做到并行处理</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;CPU提升的途径：增加晶体管密度、提升CPU主频（晶体管开关的速度）&lt;/p&gt;
&lt;p&gt;&lt;u&gt;&lt;em&gt;增加晶体管密度就需要把晶体管造的更小，这就是所谓的”制程”&lt;/em&gt;&lt;/u&gt;&lt;/p&gt;
&lt;p&gt;CPU提升带来的是功率的增加：&lt;/p&gt;
&lt;p&gt;CPU功率 &lt;strong&gt;&lt;em&gt;～
      
    
    </summary>
    
      <category term="计算机组成原理" scheme="https://jiarus.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="计算机组成原理" scheme="https://jiarus.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>计算机性能之CPU篇</title>
    <link href="https://jiarus.github.io/2019/07/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%80%A7%E8%83%BD%E4%B9%8BCPU%E7%AF%87/"/>
    <id>https://jiarus.github.io/2019/07/28/计算机性能之CPU篇/</id>
    <published>2019-07-27T19:37:00.000Z</published>
    <updated>2019-08-11T02:37:04.064Z</updated>
    
    <content type="html"><![CDATA[<p>Keyword:<br><strong>响应时间、吞吐率</strong><br><em>响应时间主要依靠提升CPU性能、吞吐率可以多增加几台机器</em><br><strong>计算性能衡量：1/响应时间</strong></p><hr><p>统计从1到100w需要花费的时间<br><code>time seq 1000000 | wc -l1000000real  0m0.101s //系统真正花费的时间user  0m0.031s //在用户态花费的时间sys   0m0.016s //程序花费的时间</code></p><hr><p><em>有可能real &lt; user + sys ，这是因为系统是多个CPU的情况，user+sys统计的在多个CPU上一共花费的时间，而real是现实中时钟过去的时间 *<br>CPU执行时间 = user + sys  = CPU时钟周期数 x CPU时钟周期时间<br>CPU时钟周期时间：计算机的主频（2.8GHz），是计算机CPU中晶体振荡器（晶振）滴答一次的时间 = 1/2.8GHz<br>CPU时钟周期数 ：指令数 x 每条指令的平均时钟周期数（每条指令平均花费的时间,Cycles Per Instruction简称CPI）<br>CPU执行时间 =  指令数 x CPI x 2.8GHz<br>**</em>结论：要提高程序的执行效率，需要从CPU的主频、单个时钟周期时间内能执行的指令数和指令总条数上来优化</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Keyword:&lt;br&gt;&lt;strong&gt;响应时间、吞吐率&lt;/strong&gt;&lt;br&gt;&lt;em&gt;响应时间主要依靠提升CPU性能、吞吐率可以多增加几台机器&lt;/em&gt;&lt;br&gt;&lt;strong&gt;计算性能衡量：1/响应时间&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;统计从1到100w需要花
      
    
    </summary>
    
      <category term="计算机组成原理" scheme="https://jiarus.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="计算机组成原理" scheme="https://jiarus.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Kafka版本号</title>
    <link href="https://jiarus.github.io/2019/07/27/Kafka%E7%89%88%E6%9C%AC%E5%8F%B7%E6%80%BB%E7%BB%93/"/>
    <id>https://jiarus.github.io/2019/07/27/Kafka版本号总结/</id>
    <published>2019-07-26T16:30:00.000Z</published>
    <updated>2019-08-04T20:02:37.221Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>kafka目前总共演进了7个大版本，分别是0.7、0.8、0.9、0.11、1.0和2.0<br>1.0以前都是4位版本号，之后改为3位版本号。如今kafka已经发行到2.3.0版本了</em></strong><br><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5oa7vgn48j30le046wf2.jpg" alt><br>Scala 2.11代表的是Scala编译器的版本</p><hr><ol><li><strong><em>0.7v</em></strong> <ol><li>只有基本的消息队列功能，不包含副本机制</li></ol></li><li><strong><em>0.8v</em></strong> <ol><li>引入了副本机制，正式进化为高可用的分布式消息队列解决方案。<strong><em>0.8.2.0</em></strong>之前的客户端API需要制定zookeeper地址，而不是broker地址。</li><li>producerAPI默认使用同步方式发送消息，异步可能会出现丢失消息的情况。建议升级到0.8.2.2</li></ol></li><li><strong><em>0.9v</em></strong> <ol><li>2015年发布的0.9.0.0版本，增加了基础安全认证和权限功能</li><li>使用Java重写了消费者客户端（<em>但存在很多BUG</em>）</li></ol></li><li><strong><em>0.10v</em></strong><ol><li>主要变更都是在kafka Streams组件上</li></ol></li><li><strong><em>0.11v</em></strong><ol><li>引入幂等性producerAPI和事务API</li><li>对kafka消息格式重构</li><li>这个版本各个组件都非常稳定了。建议使用0.11.0.3，这个是国内最主流的版本。</li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;kafka目前总共演进了7个大版本，分别是0.7、0.8、0.9、0.11、1.0和2.0&lt;br&gt;1.0以前都是4位版本号，之后改为3位版本号。如今kafka已经发行到2.3.0版本了&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;http:
      
    
    </summary>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka重设消息位移</title>
    <link href="https://jiarus.github.io/2019/07/14/Kafka%E6%B6%88%E6%81%AF%E4%BD%8D%E7%A7%BB%E8%AE%BE%E7%BD%AE/"/>
    <id>https://jiarus.github.io/2019/07/14/Kafka消息位移设置/</id>
    <published>2019-07-14T09:04:00.000Z</published>
    <updated>2019-08-14T09:33:23.672Z</updated>
    
    <content type="html"><![CDATA[<p><strong>为什么重设位移？</strong><br>开发中有时候会碰到，消息消费端出现故障统计错误，或者消息格式出现问题，需要修改消费者逻辑重新消费的情况。重设消息位移可以使消费者重新读取队列中的消息。</p><p><strong>重设位移策略</strong></p><table><thead><tr><th>纬度</th><th>策略</th><th>含义</th></tr></thead><tbody><tr><td>位移纬度</td><td>earliest</td><td>位移到队列未过期的最早消息</td></tr><tr><td></td><td>latest</td><td>位移到队列未过期的最新消息</td></tr><tr><td></td><td>current</td><td>位移到队列已消费到的最新消息</td></tr><tr><td></td><td>specified-offset</td><td>位移到指定的offset处</td></tr><tr><td></td><td>shift-by-N</td><td>位移到当前位移的前/后N处</td></tr><tr><td>时间纬度</td><td>datetime</td><td>位移到某个时间点</td></tr><tr><td></td><td>duration</td><td>位移到当前时间前指定间隔处</td></tr></tbody></table><p><strong>设置方法</strong></p><ul><li><p>通过producer API设置</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    //设置单个分区的位移</span><br><span class="line">    void seek(TopicPartition partition, long offset);</span><br><span class="line">void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata);</span><br><span class="line">    //设置多个partition位移</span><br><span class="line">    void seekToBeginning(Collection&lt;TopicPartition&gt; partitions);</span><br><span class="line">void seekToEnd(Collection&lt;TopicPartition&gt; partitions);</span><br></pre></td></tr></table></figure></li><li><p>通过kafka-consumer-groups.sh脚本设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#设置</span><br><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server kafka-host:port --group test-group --reset-offsets --all-topics -[--to-earliest/--to-latest/--to-current/--to-offset &lt;offset&gt;/--shift-by &lt;offset_N&gt;/--to-datetime &lt;2019-06-20T20:00:00&gt;/--by-duration &lt;PD0H30M0S&gt;] –execute</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;为什么重设位移？&lt;/strong&gt;&lt;br&gt;开发中有时候会碰到，消息消费端出现故障统计错误，或者消息格式出现问题，需要修改消费者逻辑重新消费的情况。重设消息位移可以使消费者重新读取队列中的消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;重设位移策略&lt;/strong&gt;&lt;/
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Java并发包常用类用法及原理</title>
    <link href="https://jiarus.github.io/2019/06/02/Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%B8%B8%E7%94%A8%E7%B1%BB%E7%94%A8%E6%B3%95%E5%8F%8A%E5%8E%9F%E7%90%86/"/>
    <id>https://jiarus.github.io/2019/06/02/Java并发包常用类用法及原理/</id>
    <published>2019-06-02T04:33:00.000Z</published>
    <updated>2019-08-13T17:27:49.314Z</updated>
    
    <content type="html"><![CDATA[<p>com.java.util.concurrent包是java5时添加的，专门处理多线程提供的工具类</p><blockquote><p><a href="#1"><strong>一、Atomic</strong></a><br><br><a href="#2"><strong>二、Lock</strong></a><br><br><a href="#3"><strong>三、BlockingQueue</strong></a><br><br><a href="#4"><strong>四、BlockDeque</strong></a><br><br><a href="#5"><strong>五、ConcurrnetMap</strong></a><br><br><a href="#6"><strong>六、CountDownLatch</strong></a><br><br><a href="#7"><strong>七、CyclicBarrier</strong></a><br><br><a href="#8"><strong>八、ExecutorService</strong></a><br><br><a href="#9"><strong>九、ForkJoinPool</strong></a><br></p></blockquote><p><a name="1"><strong>1.atomic包</strong></a></p><blockquote><p>AtomicBoolean、AtomicInteger、AtomicLong、AtomicReference<br>类提供多种方法，可以原子性地为参数取值、赋值、交换值（getAndSet）、比较并且设置值（CAS:compareAndSet）等。</p></blockquote><p>为什么需要使用atomic？<br>先说几个概念：</p><ul><li>重排序<blockquote><p>Java优化程序性能，在编译、处理和内存中对代码进行<strong>重排序</strong>，重排序是对代码的执行顺序做了修改。</p></blockquote></li><li>happens-before<blockquote><p>规定在编译、处理、内存中对代码执行重排序的规则。</p></blockquote></li><li>as-if-serial语义<blockquote><p>规定单线程中重排序和顺序执行的结果一致。</p></blockquote></li></ul><p>至于为什么需要在多线程使用atomic，有以下几点原因：</p><p>1.多个线程不能保证哪个线程先执行。因为不可见主内存值的问题，可能出现脏读的情况。</p><p>2.多线程赋值过程非原子性。因为变量在多线程中，修改一个主内存中的值，需要执行多个步骤（读取主内存，放入寄存器，修改值、赋值到主内存中），这么一来可能你在执行这个步骤的过程中，该变量被其他线程修改了，不能保证原子性。</p><p>3.使用volatile修饰变量。volatile是变量具有可见性（<del>当寄存器中修改了值，会立即通知主内存和其他寄存器修改值</del>）和有序性，查看AtomicInteger的源码，发现变量被volatile修饰。而原子性是Atomic中使用CAS（<del>修改前判断主内存的值是否和当前的值一致</del>）实现的，可见性就解决了上面问题1的脏读，有序性和原子性就解决了问题2中的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private volatile int value;</span><br><span class="line"></span><br><span class="line">public AtomicInteger(int initialValue) &#123;</span><br><span class="line">    value = initialValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a name="2"><strong>2.locks</strong></a></p><ul><li><p>ReentrantLock</p><ul><li>可重入的互斥锁，即同一线程可以多次获得该锁，线程间是互斥的。</li></ul></li><li><p>ReentrantReadWriteLock</p><ul><li>可重入的读写锁，是在ReentrantLock的基础上的增强，更细粒度地控制。在特殊场景中会使用到，分为readLock和writeLock，读读共享，读写和写写排他。</li></ul></li></ul><p>Synchronized加锁实现原理：</p><blockquote><p>Synchronized经过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。</p></blockquote><p>Synchronized和ReentrantLock的区别联系：</p><ul><li><p>相同点：<br>都是加锁实现阻塞式的同步，一个线程获取了锁，其他线程就必须等待。</p></li><li><p>不同点：</p><ul><li><p>使用上。Synchronized直接使用关键字Synchronized，ReentrantLock需要实例化，并且显示地调用lock()加锁和在finally方法块中unlock()解锁。</p></li><li><p>等待可中断。ReentrantLock可以使用lockInterruptibly()方法中断锁或者设置超时中断。</p></li><li><p>公平锁。Synchronized是非公平锁，ReentrantLock默认也是非公平锁，可以指定为公平锁。</p></li><li><p>使用Condition条件，实现线程之间的协作。</p><blockquote><p>在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。</p></blockquote></li></ul></li></ul><p><a name="3"><strong>3.BlockingQueue</strong></a></p><blockquote><p>提供了不同的插入移除检查方法，可以支持不同的返回值。</p></blockquote><table><thead><tr><th></th><th>抛异常</th><th>特定值</th><th>阻塞</th><th>超时</th></tr></thead><tbody><tr><td>插入</td><td>add(o)</td><td>offer(o)</td><td>put(o)</td><td>offer(o, timeout, timeunit)</td></tr><tr><td>移除</td><td>remove(o)</td><td>poll(o)</td><td>take(o)</td><td>poll(timeout, timeunit)</td></tr><tr><td>检查</td><td>get(o)</td><td>peek(o)</td><td>/</td><td>/</td></tr></tbody></table><blockquote><p>阻塞队列值提供一个队列可以提供遵守FIFO放入和取出的操作，如果队列满了放入就会阻塞，相反队列如果为空，取出就会阻塞。</p><p>BlockingQueue是一个接口类，具体有多种实现，主要介绍5种常用的：</p></blockquote><ul><li><p>ArrayBlockingQueue</p><blockquote><p>数组阻塞队列，故名思议是用数组实现的阻塞队列，是有界的，只能在初始化确定队列容量大小。内部只有一个reentrantLock，读和写使用同一个锁，因此效率不高。</p></blockquote></li><li><p>LinkedBlockingQueue</p><blockquote><p>链表阻塞队列，顾名思义是用链表实现的阻塞队列，但它可以是有界的也可以无界的，内部有两个reentrantLock，读写锁是分离的。性能要比ArrayBlockingQueue要高。但创建和销毁Node，高并发对GC有一定压力。</p></blockquote></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//默认的构造器</span><br><span class="line">public LinkedBlockingQueue() &#123;</span><br><span class="line">        this(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line">//指定容量的构造器</span><br><span class="line">public LinkedBlockingQueue(int capacity) &#123;</span><br><span class="line">        if (capacity &lt;= 0) throw new IllegalArgumentException();</span><br><span class="line">        this.capacity = capacity;</span><br><span class="line">        last = head = new Node&lt;E&gt;(null);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>PriorityBlockingQueue</p><blockquote><p>优先级阻塞队列。基于最小二叉堆实现，线程安全的无界队列。构造器中可以传入初始值和比较器的规则。根据比较器规则对内部元素排序。</p></blockquote></li><li><p>SynchronousQueue</p><blockquote><p>同步队列。内部只能存放一个元素。如果满了就插入就阻塞，相反如果为空取出就阻塞。</p></blockquote></li><li><p>DelayQueue</p><blockquote><p>延迟队列无界队列。内部使用优先级阻塞队列实现，只有元素过期才能取出来。并且按过期长短排序，队头的是过期最长的元素。使用ReentrantLock实现线程安全。</p></blockquote></li></ul><p><a name="4"><strong>4.BlockDeque</strong></a></p><blockquote><p>提供了不同的插入移除检查方法，可以支持不同的返回值。</p></blockquote><table><thead><tr><th></th><th>抛异常</th><th>特定值</th><th>阻塞</th><th>超时</th></tr></thead><tbody><tr><td>插入</td><td>addFirst(o)</td><td>offerFirst(o)</td><td>putFirst(o)</td><td>offerFirst(o, timeout, timeunit)</td></tr><tr><td>移除</td><td>removeFirst(o)</td><td>pollFirst(o)</td><td>takeFirst(o)</td><td>pollFirst(timeout, timeunit)</td></tr><tr><td>检查</td><td>getFirst(o)</td><td>peekFirst(o)</td><td>/</td><td>/</td></tr></tbody></table><ul><li>LinkedBlockingDeque<blockquote><p>双端链式阻塞队列。默认是无界的，也可以指定容量。该阻塞队列同时支持FIFO和FILO两种操作方式，队头和队尾都可以执行插入取出的操作。使用一把锁+两个条件维持队列的同步，和ArrayBlockingQueue的原理一样。</p></blockquote></li></ul><p><a name="5"><strong>5.ConcurrentMap</strong></a></p><blockquote><p>支持并发操作的Map。</p></blockquote><ul><li>ConcurrentHashMap 是ConcurrentMap的具体实现。<blockquote><p>1.发展。JDK1.7及之前都是使用Segment分段锁来实现的，因为Segment数量会限制并发量，而且在寻址也会执行两次hash，JDK1.8后取消Segment改为数组+链表+红黑树和CAS原子操作+synchronized实现。</p><p>2.初始化参数。</p><ul><li>initialCapacity初始化Map的容量</li><li>loadFactor负载因子</li><li>concurrencyLevel是最好情况下可以达到的并发数<del>（如果都访问的不同的Segment上）</del>。Segment的个数是大于等于的第一个2的n次方的数,即设置15。即Segment = concurrencyLevel = 2<sup>4</sup> = 16。默认情况下，initialCapacity等于16，loadFactor等于0.75，concurrencyLevel等于16.</li></ul><p>3.关于锁</p><ul><li>1.7<ul><li>Get没有加锁，因为Map中的key,value,nextHashEntry都是使用volatile修饰符修饰，多线程具有可见行。但是会进行两次Hash()方法寻址，第一次确定Segment位置，第二次确定table数组中位置。</li><li>Put使用的分段锁继承来ReentrantLock实现可重入锁。</li></ul></li><li>1.8<ul><li>Get方法同1.7相似都是没有加锁，一次hash寻址。</li><li>Put方法。使用CAS无锁机制，仅在Hash冲突时候加了synchronized同步锁。</li></ul></li></ul></blockquote></li></ul><blockquote><p>4.扩容<br>    数组容量增加一倍，并迁移链表中的数据</p></blockquote><p><a name="6"><strong>6.CountDownLatch</strong></a></p><blockquote><p>倒计时控制器(<del>自己起的名字</del>)。因为他类似于一个倒计时启动的功能。<br>初始化指定倒计时的值<code>CountDownLatch latch = new CountDownLatch(3)</code>并使用<code>latch.await()</code>等待执行，当其他其他线程调用3次<code>latch.countDown()</code>就触发主线程继续。</p></blockquote><p><a name="7"><strong>7.CyclicBarrier</strong></a></p><blockquote><p>栅栏。允许定义N个线程到达栅栏才执行某个方法。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//创建一个栅栏，这里设置2个线程都执行barrier1.await()方法后可以执行barrier1Action方法</span><br><span class="line">CyclicBarrier barrier1 = new CyclicBarrier(2, barrier1Action);</span><br></pre></td></tr></table></figure><p><a name="8"><strong>8.ExecutorService</strong></a><br>线程池服务接口，有两种具体的实现方式</p><ul><li>ThreadPoolExecutor</li></ul><table><thead><tr><th>序号</th><th>名称</th><th>类型</th><th>含义</th></tr></thead><tbody><tr><td>1</td><td>corePoolSize</td><td>int</td><td>核心线程池大小</td></tr><tr><td>2</td><td>maximumPoolSize</td><td>int</td><td>最大线程池大小</td></tr><tr><td>3</td><td>keepAliveTime</td><td>long</td><td>线程最大空闲时间</td></tr><tr><td>4</td><td>unit</td><td>TimeUnit</td><td>时间单位</td></tr><tr><td>5</td><td>workQueue</td><td>BlockingQueue<runnable></runnable></td><td>线程等待队列</td></tr><tr><td>6</td><td>threadFactory</td><td>ThreadFactory</td><td>线程创建工厂</td></tr><tr><td>7</td><td>handler</td><td>RejectedExecutionHandler</td><td>拒绝策略</td></tr></tbody></table><blockquote><p>实际上Executors类使用上述参数为他提供了多种预定义的实现。<br>  <img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5st76um2ej30w00k0dlh.jpg" width="80%"></p><p>简单介绍几种预定义实现：</p><p>1.FixedThreadPool:可以指定固定数量的核心线程，但是队列使用<code>LinkedBlockingQueue</code>是无界的，可能导致内存溢出。</p><p>2.CachedThreadPool:不限制线程的个数，要设置线程生存的周期，超过这个时间没有使用将自动回收线程。但是队列使用的是<code>SynchronousQueue</code>入队时必须出队。因为这些特性，该线程池应该用于类似于Netty中的短连接，快速处理大量耗时短的任务。</p><p>3.newSingleThreadExecutor:只创建一个线程，但是队列使用<code>LinkedBlockingQueue</code>无界队列。</p></blockquote><ul><li>ScheduledThreadPoolExecutor<blockquote><p>继承了ThreadPoolExecutor，可以设置核心和最大线程的大小，使用<code>DelayedWorkQueue</code>延迟队列。</p></blockquote></li></ul><p><a name="9"><strong>9.ForkJoinPool</strong></a></p><blockquote><p>实现了Executor接口，支持将一个大任务分为若干个子任务交给子线程处理，然后合并为一个结果集。采用了分治和递归的思想。内部维护了多个队列。<br><del>（挖坑以后用到了再详细写）</del></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;com.java.util.concurrent包是java5时添加的，专门处理多线程提供的工具类&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;#1&quot;&gt;&lt;strong&gt;一、Atomic&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&quot;#2&quot;&gt;&lt;str
      
    
    </summary>
    
      <category term="java" scheme="https://jiarus.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://jiarus.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器</title>
    <link href="https://jiarus.github.io/2019/05/08/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    <id>https://jiarus.github.io/2019/05/08/布隆过滤器/</id>
    <published>2019-05-08T07:00:00.000Z</published>
    <updated>2019-08-10T07:05:45.033Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>判断一个字符串存不存在,可以用来过滤非法字符串、垃圾邮件等</p></blockquote><p>1.使用BigSet存放hash位置信息</p><ul><li><p>初始化定义存放位置size,如4、8、16、32</p></li><li><p>有多少个size就需要多少次hash，将得到的hash值作为索引存放在set中，value为true</p></li></ul><p>2.判断是否存在，即将该字符串做hash处理，判断Bigset每个位置都为true，那么就认定该字符串存在</p><p>3.内存回收，当set占满，即每个字符串判断时都会存在，所以不能占满。<br>可以设置为百分之80，清空该set</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">package com.onedesk.dsp.utils;</span><br><span class="line"></span><br><span class="line">import java.io.*;</span><br><span class="line">import java.util.BitSet;</span><br><span class="line">import java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line">public class BloomFilter implements Serializable &#123;</span><br><span class="line">    private static final long serialVersionUID = -5221305273707291280L;</span><br><span class="line">    private final int[] seeds;</span><br><span class="line">    private final int size;</span><br><span class="line">    private final BitSet notebook;</span><br><span class="line">    private final MisjudgmentRate rate;</span><br><span class="line">    private final AtomicInteger useCount = new AtomicInteger(0);</span><br><span class="line">    private final Double autoClearRate;</span><br><span class="line">    </span><br><span class="line">    /**</span><br><span class="line">     * 默认中等程序的误判率：MisjudgmentRate.MIDDLE 以及不自动清空数据（性能会有少许提升）</span><br><span class="line">     *</span><br><span class="line">     * @param dataCount 预期处理的数据规模，如预期用于处理1百万数据的查重，这里则填写1000000</span><br><span class="line">     */</span><br><span class="line">    public BloomFilter(int dataCount) &#123;</span><br><span class="line">        this(MisjudgmentRate.MIDDLE, dataCount, 0.8);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /**</span><br><span class="line">     * @param rate          一个枚举类型的误判率</span><br><span class="line">     * @param dataCount     预期处理的数据规模，如预期用于处理1百万数据的查重，这里则填写1000000</span><br><span class="line">     * @param autoClearRate 自动清空过滤器内部信息的使用比率，传null则表示不会自动清理，</span><br><span class="line">     *                      当过滤器使用率达到100%时，则无论传入什么数据，都会认为在数据已经存在了</span><br><span class="line">     *                      当希望过滤器使用率达到80%时自动清空重新使用，则传入0.8</span><br><span class="line">     */</span><br><span class="line">    public BloomFilter(MisjudgmentRate rate, int dataCount, Double autoClearRate) &#123;</span><br><span class="line">        long bitSize = rate.seeds.length * dataCount;</span><br><span class="line">        if (bitSize &lt; 0 || bitSize &gt; Integer.MAX_VALUE) &#123;</span><br><span class="line">            throw new RuntimeException(&quot;位数太大溢出了，请降低误判率或者降低数据大小&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        this.rate = rate;</span><br><span class="line">        seeds = rate.seeds;</span><br><span class="line">        size = (int) bitSize;</span><br><span class="line">        notebook = new BitSet(size);</span><br><span class="line">        this.autoClearRate = autoClearRate;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void add(String data) &#123;</span><br><span class="line">        checkNeedClear();</span><br><span class="line">        </span><br><span class="line">        for (int i = 0; i &lt; seeds.length; i++) &#123;</span><br><span class="line">            int index = hash(data, seeds[i]);</span><br><span class="line">            setTrue(index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public boolean check(String data) &#123;</span><br><span class="line">        for (int i = 0; i &lt; seeds.length; i++) &#123;</span><br><span class="line">            int index = hash(data, seeds[i]);</span><br><span class="line">            if (!notebook.get(index)) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /**</span><br><span class="line">     * 如果不存在就进行记录并返回false，如果存在了就返回true</span><br><span class="line">     *</span><br><span class="line">     * @param data</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public boolean addIfNotExist(String data) &#123;</span><br><span class="line">        checkNeedClear();</span><br><span class="line">        </span><br><span class="line">        int[] indexs = new int[seeds.length];</span><br><span class="line">        // 先假定存在</span><br><span class="line">        boolean exist = true;</span><br><span class="line">        int index;</span><br><span class="line">        </span><br><span class="line">        for (int i = 0; i &lt; seeds.length; i++) &#123;</span><br><span class="line">            indexs[i] = index = hash(data, seeds[i]);</span><br><span class="line">            </span><br><span class="line">            if (exist) &#123;</span><br><span class="line">                if (!notebook.get(index)) &#123;</span><br><span class="line">                    // 只要有一个不存在，就可以认为整个字符串都是第一次出现的</span><br><span class="line">                    exist = false;</span><br><span class="line">                    // 补充之前的信息</span><br><span class="line">                    for (int j = 0; j &lt;= i; j++) &#123;</span><br><span class="line">                        setTrue(indexs[j]);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                setTrue(index);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        return exist;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    private void checkNeedClear() &#123;</span><br><span class="line">        if (autoClearRate != null) &#123;</span><br><span class="line">            if (getUseRate() &gt;= autoClearRate) &#123;</span><br><span class="line">                synchronized (this) &#123;</span><br><span class="line">                    if (getUseRate() &gt;= autoClearRate) &#123;</span><br><span class="line">                        notebook.clear();</span><br><span class="line">                        useCount.set(0);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void setTrue(int index) &#123;</span><br><span class="line">        useCount.incrementAndGet();</span><br><span class="line">        notebook.set(index, true);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    private int hash(String data, int seeds) &#123;</span><br><span class="line">        char[] value = data.toCharArray();</span><br><span class="line">        int hash = 0;</span><br><span class="line">        if (value.length &gt; 0) &#123;</span><br><span class="line">            </span><br><span class="line">            for (int i = 0; i &lt; value.length; i++) &#123;</span><br><span class="line">                hash = i * hash + value[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        hash = hash * seeds % size;</span><br><span class="line">        // 防止溢出变成负数</span><br><span class="line">        return Math.abs(hash);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public double getUseRate() &#123;</span><br><span class="line">        return (double) useCount.intValue() / (double) size;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    /**</span><br><span class="line">     * 清空过滤器中的记录信息</span><br><span class="line">     */</span><br><span class="line">    public void clear() &#123;</span><br><span class="line">        useCount.set(0);</span><br><span class="line">        notebook.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public MisjudgmentRate getRate() &#123;</span><br><span class="line">        return rate;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /**</span><br><span class="line">     * 分配的位数越多，误判率越低但是越占内存</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 4个位误判率大概是0.14689159766308</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 8个位误判率大概是0.02157714146322</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 16个位误判率大概是0.00046557303372</span><br><span class="line">     * &lt;p&gt;</span><br><span class="line">     * 32个位误判率大概是0.00000021167340</span><br><span class="line">     *</span><br><span class="line">     * @author lianghaohui</span><br><span class="line">     */</span><br><span class="line">    public enum MisjudgmentRate &#123;</span><br><span class="line">        // 这里要选取质数，能很好的降低错误率</span><br><span class="line">        /**</span><br><span class="line">         * 每个字符串分配4个位</span><br><span class="line">         */</span><br><span class="line">        VERY_SMALL(new int[]&#123;2, 3, 5, 7&#125;),</span><br><span class="line">        /**</span><br><span class="line">         * 每个字符串分配8个位</span><br><span class="line">         */</span><br><span class="line">        SMALL(new int[]&#123;2, 3, 5, 7, 11, 13, 17, 19&#125;), //</span><br><span class="line">        /**</span><br><span class="line">         * 每个字符串分配16个位</span><br><span class="line">         */</span><br><span class="line">        MIDDLE(new int[]&#123;2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53&#125;), //</span><br><span class="line">        /**</span><br><span class="line">         * 每个字符串分配32个位</span><br><span class="line">         */</span><br><span class="line">        HIGH(new int[]&#123;2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97,</span><br><span class="line">                101, 103, 107, 109, 113, 127, 131&#125;);</span><br><span class="line">        </span><br><span class="line">        private int[] seeds;</span><br><span class="line">        </span><br><span class="line">        private MisjudgmentRate(int[] seeds) &#123;</span><br><span class="line">            this.seeds = seeds;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        public int[] getSeeds() &#123;</span><br><span class="line">            return seeds;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        public void setSeeds(int[] seeds) &#123;</span><br><span class="line">            this.seeds = seeds;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        BloomFilter fileter = new BloomFilter(100000);</span><br><span class="line">        System.out.println(fileter.addIfNotExist(&quot;1111111111111&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;判断一个字符串存不存在,可以用来过滤非法字符串、垃圾邮件等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1.使用BigSet存放hash位置信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初始化定义存放位置size,如4、8、16、32&lt;/p&gt;
&lt;/li&gt;
&lt;
      
    
    </summary>
    
    
      <category term="算法" scheme="https://jiarus.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>innodb锁实现机制及高并发优化</title>
    <link href="https://jiarus.github.io/2019/04/28/innodb%E9%94%81%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E5%8F%8A%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96/"/>
    <id>https://jiarus.github.io/2019/04/28/innodb锁实现机制及高并发优化/</id>
    <published>2019-04-28T03:53:00.000Z</published>
    <updated>2019-08-13T04:28:31.019Z</updated>
    
    <content type="html"><![CDATA[<p><strong>innoDB行锁实现：</strong></p><ul><li>record lock<ul><li>对索引项加锁</li></ul></li><li>gap lock<ul><li>对索引之间的间隙加锁</li></ul></li><li>next-key lock<ul><li>前两种的组合，对索引和索引之间的间隙加锁</li></ul></li></ul><p><strong>高并发锁优化</strong></p><ul><li>尽量使用低级别事务隔离机制</li><li>避免行锁升级到表锁<ul><li>当使用非索引字段更新数据，就会升级为表锁。</li></ul></li><li>减少事务锁定资源量和锁定时间<ul><li>在事务中尽量把行锁放到事务最后执行。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;innoDB行锁实现：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;record lock&lt;ul&gt;
&lt;li&gt;对索引项加锁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;gap lock&lt;ul&gt;
&lt;li&gt;对索引之间的间隙加锁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;l
      
    
    </summary>
    
      <category term="mysql" scheme="https://jiarus.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="https://jiarus.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Kakfa主题管理</title>
    <link href="https://jiarus.github.io/2019/04/26/Kakfa%E4%B8%BB%E9%A2%98%E7%AE%A1%E7%90%86/"/>
    <id>https://jiarus.github.io/2019/04/26/Kakfa主题管理/</id>
    <published>2019-04-26T12:13:00.000Z</published>
    <updated>2019-08-06T19:57:16.707Z</updated>
    
    <content type="html"><![CDATA[<p><strong>创建Topic</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure><p>kafka2.2之后推荐使用<code>--bootstrap-server</code>代替<code>--zookeeper</code>，因为通过前者创建可以控制权限，只和Broker打交道也是官方之后标准。</p><p><strong>查看Topic列表</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --list</span><br></pre></td></tr></table></figure><p><strong>查看Topic详情</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt;</span><br></pre></td></tr></table></figure><p><strong>删除Topic</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic &lt;topic_name&gt;</span><br></pre></td></tr></table></figure><p><strong>增加Topic分区</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt; 新分区数 &gt;</span><br></pre></td></tr></table></figure><p>kafka不允许增加分区。因为多个broker节点都冗余有分区的数据，减少分区数需要操作多个broker且需要迁移该分区数据到其他分区。如果是按消息key hash选的分区，那么迁移就不知道迁到哪里了，因为只有业务代码可以决定放在哪。已经被大佬肯定了，应该没错。:)<br><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5qlb5wdfxj31380d0aca.jpg" alt></p><p><strong>修改Topic参数</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes=10485760</span><br></pre></td></tr></table></figure><p>设置允许最大消息大小</p><p><strong>变更Topic副本数</strong></p><p>使用kafka-reassign-partitions</p><p><strong>修改Topic限速</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &apos;leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600&apos; --entity-type brokers --entity-name 0</span><br></pre></td></tr></table></figure><p>主要限制Leader和Follower的副本使用的带宽。broker 0 代表某一个节点，多个需要每个都单独执行命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &apos;leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*&apos; --entity-type topics --entity-name test</span><br></pre></td></tr></table></figure><p>同时还要设置要限速的副本*代表所有副本</p><p><strong>内部Topic</strong><br>__consumer_offsets是用来记录consumer的offset值，默认创建50个分区。不需要手动管理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;创建Topic&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Mysql索引优化</title>
    <link href="https://jiarus.github.io/2019/04/25/Mysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/"/>
    <id>https://jiarus.github.io/2019/04/25/Mysql索引优化/</id>
    <published>2019-04-25T04:31:00.000Z</published>
    <updated>2019-08-13T04:58:20.575Z</updated>
    
    <content type="html"><![CDATA[<p><strong>索引使用存在的问题：</strong></p><ul><li>回表<ul><li>innodb默认使用主键索引是聚簇索引，其他索引是非聚簇索引。当使用非聚簇索引查询时，先在B+Tree叶子节点上获得主键id，然后根据主键id再去聚簇索引查询叶子节点的行数据。这两次查询就称作回表。</li></ul></li><li>页分裂<ul><li>B+Tree数据存放在叶子节点上，叶子节点大小为16K会自动分裂生成更多叶子节点，这样会导致内存碎片，索引结构不紧凑，查询效率低。</li></ul></li></ul><p><strong>索引优化：</strong></p><ul><li><p>建立整型自增主键</p><ul><li><p>如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引、如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)</p></li><li><p>如果我们使用了随机的UUID来作为主键，因为是无序的，如果某个节点达到来16k,插入就需要移动数据，这样事实上在聚簇数据上会容易产生B+Tree的分裂、也容易浪费系统性能。</p></li></ul></li><li><p>使用覆盖索引</p><ul><li>比如要查询a,b,c三个列的数据，可以在a,b,c三列上建立组合索引，可以直接从这三列的组合索引上获得数据，不需要在进行回表查询。</li></ul></li><li><p>使用前缀索引</p><ul><li><p>如果在大字段上建立索引，会导致每个页上存放的索引数少，那么就需要查询多个页，降低了查询效率。可以使用前缀索引，只使用列的部分数据建立索引。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 设置前缀索引</span><br><span class="line">alter table demo add index name( user_name(4) )</span><br></pre></td></tr></table></figure><blockquote><p>注意：order by 不能使用前缀索引。也不能把前缀索引作覆盖索引。</p></blockquote></li></ul></li><li><p>避免索引失效</p><ul><li>复合索引按最左匹配原则</li><li>复合索引使用or，如果or前后包含了非复合索引字段，也不能使用复合索引。</li></ul></li></ul><p><strong>特殊情况：</strong></p><ul><li>当发生回表时候，假如查询的的数据行数很多(超过整张表20%)，mysql优化器会转为使用聚簇索引，如果发现mysql优化的结果不如使用辅助索引来的快，那么可以手动使用命令<code>force index</code>强制使用辅助索引。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;索引使用存在的问题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;回表&lt;ul&gt;
&lt;li&gt;innodb默认使用主键索引是聚簇索引，其他索引是非聚簇索引。当使用非聚簇索引查询时，先在B+Tree叶子节点上获得主键id，然后根据主键id再去聚簇索引查询叶子节点的行
      
    
    </summary>
    
      <category term="mysql" scheme="https://jiarus.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="https://jiarus.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Golang中遍历非指针对象的坑</title>
    <link href="https://jiarus.github.io/2019/04/20/Golang%E4%B8%AD%E9%81%8D%E5%8E%86%E9%9D%9E%E6%8C%87%E9%92%88%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9D%91/"/>
    <id>https://jiarus.github.io/2019/04/20/Golang中遍历非指针对象的坑/</id>
    <published>2019-04-20T10:47:00.000Z</published>
    <updated>2019-08-11T00:56:51.988Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间写了个递归树，中间遇到了个坑，按逻辑看是没问题，没想到结果不对。</p><blockquote><p><code>for _, v := range tree</code>我在遍历这个tree数组的时候传递的是数组对象，修改了数组的内容但返回时发现没有变化。这就是golang和java的差别，遍历的时候如果是非指针对象，那么golang会copy一个副本v，你修改的只是v的值，除非你修改完再重新放入数组，否则结果是不会变的。或者使用指针传递，使用数组的指针就没问题了。</p></blockquote><p>这应该是golang和java思想的不同之处，golang处处都应该尽量使用指针，特别是大对象。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">func genGeoTree(arr *[]entity.GeoCommon) []*entity.GeoTree &#123;</span><br><span class="line">root := buildGeoRoot(arr)</span><br><span class="line">buildGeoChildren(arr, root)</span><br><span class="line">return root</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func buildGeoRoot(arr *[]entity.GeoCommon) []*entity.GeoTree &#123;</span><br><span class="line">var pNodes []*entity.GeoTree</span><br><span class="line">for _, v := range *arr &#123;</span><br><span class="line">if v.PCode == 0 &#123;</span><br><span class="line">var child entity.GeoTree</span><br><span class="line">child.Code = v.Code</span><br><span class="line">child.Name = v.Name</span><br><span class="line">child.Sort = v.Sort</span><br><span class="line">child.PCode = v.PCode</span><br><span class="line">pNodes = append(pNodes, &amp;child)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return pNodes</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func buildGeoChildren(arr *[]entity.GeoCommon, tree []*entity.GeoTree) &#123;</span><br><span class="line">for _, v := range tree &#123;</span><br><span class="line">pNodes := make([]*entity.GeoTree, 0)</span><br><span class="line">for _, vv := range *arr &#123;</span><br><span class="line">if vv.PCode == v.Code &#123;</span><br><span class="line">var child entity.GeoTree</span><br><span class="line">child.Code = vv.Code</span><br><span class="line">child.Name = vv.Name</span><br><span class="line">child.Sort = vv.Sort</span><br><span class="line">child.PCode = vv.PCode</span><br><span class="line">pNodes = append(pNodes, &amp;child)</span><br><span class="line">buildGeoChildren(arr, pNodes)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">v.Children = pNodes</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段时间写了个递归树，中间遇到了个坑，按逻辑看是没问题，没想到结果不对。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;for _, v := range tree&lt;/code&gt;我在遍历这个tree数组的时候传递的是数组对象，修改了数组的内容但返回时发现没有变化。这就
      
    
    </summary>
    
      <category term="golang" scheme="https://jiarus.github.io/categories/golang/"/>
    
    
      <category term="golang" scheme="https://jiarus.github.io/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消费者组和Rebalance</title>
    <link href="https://jiarus.github.io/2019/04/18/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84/"/>
    <id>https://jiarus.github.io/2019/04/18/Kafka消费者组/</id>
    <published>2019-04-18T03:05:00.000Z</published>
    <updated>2019-08-06T03:32:21.402Z</updated>
    
    <content type="html"><![CDATA[<h6 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h6><blockquote><p>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制</p></blockquote><p>特性：</p><p>1.一个组下可以包含多个消费者实例。可以是消费者进程，也可以是消费者线程。</p><p>2.GroupID是个字符串，标识唯一的group。</p><p>3.Topic下的分区只能被某个Group的一个Consumer消费。一个Consumer可以消费多个分区，即分区和消费者是多对一的关系。所以Kafka可以实现消息队列（一个消费者属于单个Group）,也可以实现发布/订阅模型（一个消费者属于多个Group）。</p><p><strong>group中的offset</strong><br>老版本中保存在Zookeeper中，新版本保存在Broker节点Topic中。</p><h6 id="Rebalance"><a href="#Rebalance" class="headerlink" title="Rebalance"></a>Rebalance</h6><blockquote><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p></blockquote><p>触发条件:</p><p>1.Group下的consumer成员变更</p><p>2.Topic变更</p><p>3.Topic分区变更</p><p>影响：</p><p>Stop The World.即在Rebalance时kafka会停止所有的服务，因为当前版本的Kafka触发Rebalance时候会重新分配所有的Consumer对应的分区，并不是像一致性哈希（一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。）那样尽量保证其他节点不影响。所以要尽量避免发生Rebalance的发生。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;消费者组&quot;&gt;&lt;a href=&quot;#消费者组&quot; class=&quot;headerlink&quot; title=&quot;消费者组&quot;&gt;&lt;/a&gt;消费者组&lt;/h6&gt;&lt;blockquote&gt;
&lt;p&gt;Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制&lt;/p&gt;
&lt;/b
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>mysql如何避免死锁</title>
    <link href="https://jiarus.github.io/2019/04/13/mysql%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81/"/>
    <id>https://jiarus.github.io/2019/04/13/mysql如何避免死锁/</id>
    <published>2019-04-13T04:33:00.000Z</published>
    <updated>2019-08-13T18:26:02.991Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Mysql死锁：</strong></p><p>通常是多个事务互相持有对方不兼容的锁导致的。</p><p>在可重复度RR及以上级别会生成gap lock 和 next-key lock<br>兼容矩阵图（横向是已持有锁，纵向是请求的锁）</p><p><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5ym0mrqp2j311q0b80uw.jpg" alt></p><p><strong>发生死锁的条件：</strong><br>situation1:<br><img src="http://ww4.sinaimg.cn/large/006tNc79ly1g5y4b7d48xj31150u0438.jpg" alt><br>AB都获得GK，插入时都想获得IK,等待对方的GK释放,导致死锁。</p><p>situation2:<br><img src="http://ww1.sinaimg.cn/large/006tNc79ly1g5y4pfu3rhj311q06yab9.jpg" alt><br><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5y4qcec9qj311u0bqjtb.jpg" alt><br><strong>如何避免：</strong></p><ul><li>尽量使用主键更新数据，防止使用非聚簇索引回表时和使用聚簇索引冲突造成死锁。</li><li>在允许幻读和不可重复度的情况下，尽量使用RC的隔离级别，避免gap lock造成的死锁。</li><li>避免长事务，将事务拆解</li><li>设置锁超时等待<code>innodb_lock_wait_timeout</code></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Mysql死锁：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常是多个事务互相持有对方不兼容的锁导致的。&lt;/p&gt;
&lt;p&gt;在可重复度RR及以上级别会生成gap lock 和 next-key lock&lt;br&gt;兼容矩阵图（横向是已持有锁，纵向是请求的锁）&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
      <category term="mysql" scheme="https://jiarus.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="https://jiarus.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>Kafka幂等性和事务</title>
    <link href="https://jiarus.github.io/2019/04/07/Kafka%E5%B9%82%E7%AD%89%E6%80%A7%E5%92%8C%E4%BA%8B%E5%8A%A1/"/>
    <id>https://jiarus.github.io/2019/04/07/Kafka幂等性和事务/</id>
    <published>2019-04-07T05:42:00.000Z</published>
    <updated>2019-08-06T02:04:27.552Z</updated>
    
    <content type="html"><![CDATA[<h6 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h6><blockquote><p>幂等性值多次执行某个操作，每次执行的结果都和第一次一样。Kafka可以在Producer端设置幂等性，<em>0.11.0.0</em>之后加入的新功能，<code>enable.idempotence = true</code>设置后Producer自动会对你的消息进行去重。但是只能保证单分区上的幂等性，即一个幂等性Producer只能保证某个Topic下的一个分区内不会出现重复数据，无法实现多分区幂等性。还有只能保证单会话幂等性，Producer重启后就不能与之前的数据共享幂等性。</p></blockquote><p><em>个人认为在消息者端实现幂等性，可以最大程度避免重复消费。</em></p><h6 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h6><blockquote><p>事务Producer可以保证跨会话和跨分区的幂等性。和幂等性设置一样<code>enable.idempotence = true</code>，设置Producer端<code>transcational.id</code>,业务代码中也要手动开启和提交事务。在Consumer端设置<code>isolation.level = read_committed</code>。一般是在Kafka Streams 流处理中使用，保证精确的一次语义。平时一般不会使用因为性能不太高。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;幂等性&quot;&gt;&lt;a href=&quot;#幂等性&quot; class=&quot;headerlink&quot; title=&quot;幂等性&quot;&gt;&lt;/a&gt;幂等性&lt;/h6&gt;&lt;blockquote&gt;
&lt;p&gt;幂等性值多次执行某个操作，每次执行的结果都和第一次一样。Kafka可以在Producer端设置幂等性，&lt;e
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消息无丢失/重复消费配置</title>
    <link href="https://jiarus.github.io/2019/04/06/Kafka%E6%B6%88%E6%81%AF%E6%97%A0%E4%B8%A2%E5%A4%B1%E9%85%8D%E7%BD%AE/"/>
    <id>https://jiarus.github.io/2019/04/06/Kafka消息无丢失配置/</id>
    <published>2019-04-06T01:00:00.000Z</published>
    <updated>2019-08-13T18:34:50.848Z</updated>
    
    <content type="html"><![CDATA[<h6 id="消息丢失-重复消费的场景："><a href="#消息丢失-重复消费的场景：" class="headerlink" title="消息丢失/重复消费的场景："></a>消息丢失/重复消费的场景：</h6><ul><li><p>提交消息失败</p><ul><li><p>使用<code>producer.send(msg)</code>提交消息。因为没有回调结果，这时可能消息broker因为网络波动并没有收到，此时消息就丢失了。所以建议使用有回调函数的<code>producer.send(msg,callback)</code>。</p></li><li><p>自动提交offset。可能你使用了多线程处理消息并且是自动提交。如果某个线程处理失败，并且没有显示地通知那么自动提交后就会丢失消息。</p></li></ul></li><li><p>Broker端丢失消息</p><ul><li>使用了unclean leader 选举。</li><li>offset超前，超过了HighWater（真实已消费的位置）。再次消费会从offset位置开始，中间的消息就丢失了。相反offset落后与HW就导致重复消费。    </li></ul></li></ul><h6 id="最佳实践："><a href="#最佳实践：" class="headerlink" title="最佳实践："></a>最佳实践：</h6><p> 1～3 producer端参数<br> 4～8 broker端参数</p><p> 1.不使用<code>producer.send(msg)</code>提交消息，一定使用带有回调函数方式提交。</p><p> 2.使用<code>acks = all</code>,意味着在ISR中的所有的副本broker都接收消息才认为提交成功。</p><p> 3.设置producer端的retries值&gt;0，即设置重试次数。</p><p> 4.设置<code>unclean.leader.election.enable=false</code>禁止落后太多的副本选举成为leader，unclean leader指的是落后于最新消息的节点，如果它被选作leader那就肯定会丢失数据。有利有弊，这个参数发挥作用的情况只有当ISR(副本集合)中没有副本，才会执行unclean选举，如果不选举那么就会导致整个broker挂掉，失去高可用性。但一般还是要禁止掉，同时增加多个replicas(副本)个数来保证ISR中有正常的副本。</p><p> 5.设置<code>replication.factor=3</code>副本个数，可以冗余消息到其他broker上。</p><p> 6.设置<code>min.insync.replicas&gt;1</code>,设置消息要写入多少个副本才算成功。生产环境最好要&gt;1。</p><p> 7.确保<code>replication.factor &gt; min.insync.replicas</code> 即副本个数大于需成功写入的个数。生产环境设置<code>replication.factor = min.insync.replicas + 1</code>这样可以保证有一个副本挂掉的情况下仍然可以提交数据。</p><p> 8.设置<code>enable.auto.commit = false</code> 即设置手动提交offset方式，对单consumer多线程的情况很关键。</p><p>在提交消息时，也建议同时使用异步提交+同步提交的策略。保证性能和安全性！</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    try &#123;</span><br><span class="line">           while(true) &#123;</span><br><span class="line">             ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));</span><br><span class="line">             process(records); // 处理消息</span><br><span class="line">             commitAysnc(); // 使用异步提交规避阻塞</span><br><span class="line">            &#125;</span><br><span class="line">&#125; catch(Exception e) &#123;</span><br><span class="line">            handle(e); // 处理异常</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                   consumer.commitSync(); // 最后一次提交使用同步阻塞式提交</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">     consumer.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h6 id=&quot;消息丢失-重复消费的场景：&quot;&gt;&lt;a href=&quot;#消息丢失-重复消费的场景：&quot; class=&quot;headerlink&quot; title=&quot;消息丢失/重复消费的场景：&quot;&gt;&lt;/a&gt;消息丢失/重复消费的场景：&lt;/h6&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;提交消息失败&lt;/p&gt;
&lt;ul&gt;
&lt;
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>广告竞价为什么取第二高价？</title>
    <link href="https://jiarus.github.io/2019/03/05/%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%96%E7%AC%AC%E4%BA%8C%E9%AB%98%E4%BB%B7%EF%BC%9F/"/>
    <id>https://jiarus.github.io/2019/03/05/广告竞价为什么取第二高价？/</id>
    <published>2019-03-05T13:38:00.000Z</published>
    <updated>2019-08-11T13:40:16.278Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>广义第二高阶 规定价高者得，但只需按照第二报价支付。</p></blockquote><p>其一，GSP能让竞价成功的广告主失去调低出价的动力，因为无论是否调低出价，自己的真实出价都不会改变，除非竞价失败；</p><p>其二，GSP还能让未竞价成功的广告主失去以最小竞价单位递增出价的动力，因为这种出价策略很难赢得竞价。因此，GSP被称为单位置最优竞价策略。由于GSP的这种优势，现在几乎所有的互联网竞价广告都采用这种方式。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;广义第二高阶 规定价高者得，但只需按照第二报价支付。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其一，GSP能让竞价成功的广告主失去调低出价的动力，因为无论是否调低出价，自己的真实出价都不会改变，除非竞价失败；&lt;/p&gt;
&lt;p&gt;其二，GSP还能让未竞
      
    
    </summary>
    
    
      <category term="广告系统" scheme="https://jiarus.github.io/tags/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Kafka分区机制原理</title>
    <link href="https://jiarus.github.io/2019/03/02/Kafka%E5%88%86%E5%8C%BA%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>https://jiarus.github.io/2019/03/02/Kafka分区最佳实践/</id>
    <published>2019-03-02T15:57:00.000Z</published>
    <updated>2019-08-11T02:38:54.482Z</updated>
    
    <content type="html"><![CDATA[<p>kafka消息组织结构：<br>主题-分区-消息<br><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5p8tk3wyej30bq07lwf0.jpg" alt><br>一、为什么分区？</p><ul><li>提供负载均衡、动态伸缩的能力</li><li>支持局部消息顺序消费</li></ul><p>二、分区策略</p><ul><li><p>默认分区策略</p><ul><li><p>轮询（Round-robin）是javaProducerAPI默认策略</p></li><li><p>随机（Randomness）</p></li><li><p>按消息键保存。自定义每条消息的消息键，消息键代表业务类型，使相同类型的业务放到同一个partition。因为一个分区只能针对同一个消费者，那么该消费者的消息就是有序的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">   #按key类型划分</span><br><span class="line">   List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">   List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">     return Math.abs(key.hashCode()) % partitions.size();</span><br><span class="line">     </span><br><span class="line">#按地区分区,同理可以按Ip地域划分partition。</span><br><span class="line">   List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">   return partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();</span><br></pre></td></tr></table></figure></li></ul></li><li><p>自定义分区策略</p><blockquote><p>需要实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口，设置并设置<code>partitioner.class</code>值为该实现类全路径类名</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;kafka消息组织结构：&lt;br&gt;主题-分区-消息&lt;br&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/006tNc79ly1g5p8tk3wyej30bq07lwf0.jpg&quot; alt&gt;&lt;br&gt;一、为什么分区？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提供负
      
    
    </summary>
    
      <category term="kafka" scheme="https://jiarus.github.io/categories/kafka/"/>
    
    
      <category term="kafka" scheme="https://jiarus.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>重写equals和hashCode引发的思考</title>
    <link href="https://jiarus.github.io/2019/01/28/%E5%85%B3%E4%BA%8E%E9%87%8D%E5%86%99equals/"/>
    <id>https://jiarus.github.io/2019/01/28/关于重写equals/</id>
    <published>2019-01-28T04:47:00.000Z</published>
    <updated>2019-08-12T19:00:14.811Z</updated>
    
    <content type="html"><![CDATA[<p><strong>关于重写equals方法</strong></p><blockquote><p>最近小伙伴问了我个问题：<br>在Set里存放对象，如果有两个对象属性相同，那么怎么能保证只存在一个对象？<br>HashSet是基于HashMap实现的，所以要看看HashMap的源码</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">final V putVal(int hash, K key, V value, boolean onlyIfAbsent,</span><br><span class="line">                   boolean evict) &#123;</span><br><span class="line">        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;</span><br><span class="line">        if ((tab = table) == null || (n = tab.length) == 0)</span><br><span class="line">            n = (tab = resize()).length;</span><br><span class="line">            //判断该hashCode的key是否存在</span><br><span class="line">        if ((p = tab[i = (n - 1) &amp; hash]) == null)</span><br><span class="line">            tab[i] = newNode(hash, key, value, null);</span><br><span class="line">        else &#123;</span><br><span class="line">            Node&lt;K,V&gt; e; K k;</span><br><span class="line">            //如果该hashCode存在，调用equals比较key的值</span><br><span class="line">            if (p.hash == hash &amp;&amp;</span><br><span class="line">                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                e = p;</span><br><span class="line">            else if (p instanceof TreeNode)</span><br><span class="line">                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span><br><span class="line">            else &#123;</span><br><span class="line">                for (int binCount = 0; ; ++binCount) &#123;</span><br><span class="line">                    if ((e = p.next) == null) &#123;</span><br><span class="line">                        p.next = newNode(hash, key, value, null);</span><br><span class="line">                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st</span><br><span class="line">                            treeifyBin(tab, hash);</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    if (e.hash == hash &amp;&amp;</span><br><span class="line">                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                        break;</span><br><span class="line">                    p = e;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (e != null) &#123; // existing mapping for key</span><br><span class="line">                V oldValue = e.value;</span><br><span class="line">                if (!onlyIfAbsent || oldValue == null)</span><br><span class="line">                    e.value = value;</span><br><span class="line">                afterNodeAccess(e);</span><br><span class="line">                return oldValue;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        ++modCount;</span><br><span class="line">        if (++size &gt; threshold)</span><br><span class="line">            resize();</span><br><span class="line">        afterNodeInsertion(evict);</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到，HashMap是根据hashCode来确定在Node数组中的位置，那么要使HashSet能够对对象去重，就首先需要重写对象的Hash方法，使相同值的对象的HashCode相等，其次还需要重写equals方法，因为即使hashCode相同还是会存放到Map中，这种情况属于Hash冲突，会使用链表存放该对象。</p><p>HashCode和equals的关系？</p><ul><li>以下是我的理解<blockquote><p>equals比较变量或者对象是否“相同”，这个相同是偏向于业务上的相同，和人理解的“相同”是一个概念。计算机判断的“相同”是hashCode是一致，但如果一个对象,那么计算机并不知道怎么判断他们是否相同<del>(总不能比较对象字节流吧。。)</del>，那么就只能使用Object的hashCode方法判断值是否一致。如果没重写就会导致计算机认为是不同的对象。<strong>所以就有了重写equals()一定要重写hashcode()的说法了</strong>。但注意hashCode相同equals不一定要相同，因为这个是由于hash算法的优劣决定的。</p></blockquote></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//下面是Object的生成hashCode方法，根据内存地址生成</span><br><span class="line">/** This is stated explicitly here because it is important for</span><br><span class="line">     implementations to understand that equals() and hashCode() must</span><br><span class="line">     absolutely, positively work properly -- i.e., two Address</span><br><span class="line">     objects representing the same address are both equal (via</span><br><span class="line">     equals()) and have the same hash code. */</span><br><span class="line"> public int hashCode();</span><br></pre></td></tr></table></figure><p><strong>注意Integer等包装类型：</strong></p><p>1.Integer 类型的值在[-128,127] 期间,Integer 用 “==”是可以的   ， Integer  与 int 类型比较（==）比较的是值。Integer和int比较会自动拆箱，可以用==或equals</p><p>2.大于127比较两个Integer用intValue 然后在 == 或者直接equals</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;关于重写equals方法&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最近小伙伴问了我个问题：&lt;br&gt;在Set里存放对象，如果有两个对象属性相同，那么怎么能保证只存在一个对象？&lt;br&gt;HashSet是基于HashMap实现的，所以要看看Hash
      
    
    </summary>
    
      <category term="java" scheme="https://jiarus.github.io/categories/java/"/>
    
    
      <category term="java" scheme="https://jiarus.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>@Transcational注解原理</title>
    <link href="https://jiarus.github.io/2019/01/18/Transcational%E6%B3%A8%E8%A7%A3%E5%8E%9F%E7%90%86/"/>
    <id>https://jiarus.github.io/2019/01/18/Transcational注解原理/</id>
    <published>2019-01-18T11:20:00.000Z</published>
    <updated>2019-08-10T06:59:43.130Z</updated>
    
    <content type="html"><![CDATA[<p><strong>@Transcational注解原理</strong></p><p>运行配置@Transactional注解的测试类的时候，具体会发生如下步骤</p><ul><li><p>事务开始时，通过AOP机制，生成一个代理connection对象，并将其放入DataSource实例的某个与DataSourceTransactionManager相关的某处容器中。在接下来的整个事务中，客户代码都应该使用该connection连接数据库，执行所有数据库命令(不使用该connection连接数据库执行的数据库命令，在本事务回滚的时候得不到回滚)</p></li><li><p>事务结束时，回滚在第1步骤中得到的代理connection对象上执行的数据库命令，然后关闭该代理connection对象</p></li></ul><p>根据上面所述，我们所使用的客户代码应该具有如下能力：</p><ul><li><p>每次执行数据库命令的时候<br>如果在事务的上下文环境中，那么不直接创建新的connection对象，而是尝试从DataSource实例的某个与DataSourceTransactionManager相关的某处容器中获取connection对象；在非事务的上下文环境中，直接创建新的connection对象</p></li><li><p>每次执行完数据库命令的时候<br>如果在事务的上下文环境中，那么不直接关闭connection对象，因为在整个事务中都需要使用该connection对象，而只是释放本次数据库命令对该connection对象的持有；在非事务的上下文环境中，直接关闭该connection对象</p></li></ul><p><strong>@Transactional 通常在哪里使用？</strong></p><blockquote><p>Spring团队的建议是你在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。你当然可以在接口上使用 @Transactional 注解，但是这将只能当你设置了基于接口的代理时它才生效。因为注解是 不能继承 的，这就意味着如果你正在使用基于类的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装（将被确认为严重的）。因 此，请接受Spring团队的建议并且在具体的类上使用 @Transactional 注解。</p><p>可以在类或者方法上使用，不推荐在接口上使用。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;@Transcational注解原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;运行配置@Transactional注解的测试类的时候，具体会发生如下步骤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;事务开始时，通过AOP机制，生成一个代理connection对象，并将其放入Da
      
    
    </summary>
    
      <category term="spring" scheme="https://jiarus.github.io/categories/spring/"/>
    
    
      <category term="spring" scheme="https://jiarus.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>Redis Debug 命令</title>
    <link href="https://jiarus.github.io/2019/01/10/Redis-Debug-%E5%91%BD%E4%BB%A4/"/>
    <id>https://jiarus.github.io/2019/01/10/Redis-Debug-命令/</id>
    <published>2019-01-10T06:45:00.000Z</published>
    <updated>2019-08-11T13:08:02.055Z</updated>
    
    <content type="html"><![CDATA[<p>查看某一个Key的Debug信息，使用<code>debug object [key]</code><br><img src="http://ww2.sinaimg.cn/large/006tNc79ly1g5ukxhidosj30ts06mq3r.jpg" alt></p><p>查看redis内存使用情况使用<code>info memeroy</code><br><img src="http://ww3.sinaimg.cn/large/006tNc79ly1g5ukxk9mpej30860azmy5.jpg" alt></p><ul><li>used_memory_human: 已使用内存（格式化可读性的）</li><li>used_memory_peak_human: 使用最高峰值</li><li>total_system_memory_human: 总内存</li><li>used_memory_rss_huamn: Redis进程占用内存</li><li>evicted_keys: 因为内存满而被驱逐/回收的key</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;查看某一个Key的Debug信息，使用&lt;code&gt;debug object [key]&lt;/code&gt;&lt;br&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/006tNc79ly1g5ukxhidosj30ts06mq3r.jpg&quot; alt&gt;&lt;/p
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Tomcat线程池原理</title>
    <link href="https://jiarus.github.io/2018/12/02/Tomcat%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86/"/>
    <id>https://jiarus.github.io/2018/12/02/Tomcat线程池原理/</id>
    <published>2018-12-01T18:05:00.000Z</published>
    <updated>2019-08-14T18:35:29.537Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Tomcat线程池扩充了java的ThreadPoolExecutor</strong></p><ul><li>tomcat定制了自己的Queue（重写了LinkedBlockingQueue）和ThreadFactory</li><li>最大线程数（maximumPoolSize）线程池大小有控制，可以通过参数设置</li></ul><p><strong>处理流程：</strong></p><ul><li>前corePoolSize个任务入队，同时在线程池创建一个线程。</li><li>之后的任务直接放入队列，不创建线程，当任务队列满了就开始创建临时线程。</li><li>当达到最大线程数，<strong>仍旧尝试向队列添加任务</strong>（这点和原生线程池有所不同）。</li><li>添加失败,拒绝服务。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Tomcat线程池扩充了java的ThreadPoolExecutor&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tomcat定制了自己的Queue（重写了LinkedBlockingQueue）和ThreadFactory&lt;/li&gt;
&lt;li&gt;最大线程数（
      
    
    </summary>
    
      <category term="tomcat" scheme="https://jiarus.github.io/categories/tomcat/"/>
    
    
      <category term="tomcat" scheme="https://jiarus.github.io/tags/tomcat/"/>
    
  </entry>
  
</feed>
